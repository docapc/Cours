%\listfiles
\documentclass[a4paper,12pt,twoside]{article}

%% packages
\usepackage[french]{babel}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{amsmath,amssymb,mathrsfs} 
%\usepackage{import}
\usepackage{float, subfig, caption}
\usepackage{libertine}
\usepackage{fancybox}
\usepackage{graphicx}
\usepackage{xcolor} %/ pour \Definecolor
\usepackage[pdftex,final=true]{hyperref}
%\usepackage[]{hyperref}
\hypersetup{
colorlinks=true,
linkcolor=blue,
urlcolor=magenta, %/ file: adopte également cette couleur
filecolor=cyan, % ne fonctionne qu'avec run:, 
%citecolor=red
}
\urlstyle{same}
\usepackage[french]{minitoc}
\usepackage[acronym,toc,automake]{glossaries} % acronym pour les acronymes et toc pour inclusion des glossary dans la table des matières
\usepackage[left=2cm,right=2cm,top=2cm,bottom=2cm]{geometry}
%\usepackage{minted} % pour code avec coloration dans le texte
\usepackage{url} % Pour avoir de belles url
%% package ticks spécifiquement (pour les schémas) 
%\usepackage{tikz}%
%\usepackage[top=2cm,bottom=2cm]{geometry}
%% paramètres tikz
%\usetikzlibrary{patterns,decorations.pathreplacing,shapes.misc}
%\usetikzlibrary{calc}
%\tikzset{cross/.style={cross out, draw=black, minimum size=2*(#1-\pgflinewidth), inner sep=0pt, outer sep=0pt},
%default radius will be 1pt. 
%cross/.default={5pt}}
% \definecolor{Gray}{gray}{0.9}
% \definecolor{LightCyan}{rgb}{0.88,1,1}
% \newcommand{\RN}[1]{\textup{\uppercase\expandafter{\romannumeral#1}}}    

%% Macros comme variable
%\newcommand{\editorpath}{C:/Program Files/Notepad++/notepad++.exe}
\newcommand{\exemplepath}{../Exercices}
\newcommand{\urlcolor}{magenta}  % couleur des liens https
\newcommand{\filecolor}{cyan} % couleur des liens file: file
\newcommand{\pdfcolor}{red} % couleur des liens file: .pdf
\newcommand{\foldercolor}{orange} % couleur des liens file: Folder
\newcommand{\cscolor}{green!60!black} % couleur des liens file: .cs
\newcommand{\slncolor}{violet} % couleur des liens file: .sln
\newcommand{\keycolor}{purple} % couleur des liens  de type mot clefs
%% Macros commun
\newcommand{\incode}[1]{{\footnotesize\ttfamily #1}} % pour du pseudo-code simple
\newcommand{\rem}[2]{\noindent\underline{Remarque} : \textit{#1}.\\ \indent #2}
\newcommand{\note}[1]{\noindent\underline{Note} : \\ \indent #1}
\newcommand{\defi}[2]{\noindent\underline{Définition} : \textbf{#1}.\\ \indent #2}
\newcommand{\slide}[2]{\textbullet ~ Slide n°#1 : \indent #2}
%% Macro spécifiques à ce fichier (pas forcément) : pour fonctionner il faut que le fichier ai été ouvert diretcement dans le dossier du .tex ...
\newcommand{\fileref}[2]{\hypersetup{urlcolor=\filecolor}\href{file: #1}{#2}\hypersetup{urlcolor=\urlcolor}}
\newcommand{\pdfref}[2]{\hypersetup{urlcolor=\pdfcolor}\href{file: #1.pdf}{#2.pdf}\hypersetup{urlcolor=\urlcolor}}
\newcommand{\csref}[2]{\hypersetup{urlcolor=\cscolor}\href{file:\exemplepath /#1.cs}{#2.cs}\hypersetup{urlcolor=\urlcolor}}
\newcommand{\slnref}[2]{\hypersetup{urlcolor=\slncolor}\href{file:\exemplepath /#1.sln}{#2.sln}\hypersetup{urlcolor=\urlcolor}}
\newcommand{\folderref}[2]{\hypersetup{urlcolor=\foldercolor}\href{file:\exemplepath /#1/.}{#2}\hypersetup{urlcolor=\urlcolor}}
\newcommand{\keyref}[2]{\hypersetup{urlcolor=\keycolor} \href{#1}{\textbf{#2}}\hypersetup{urlcolor=\urlcolor}}
\newcommand{\keyword}[3]{\noindent\underline{Mot clef} : \keyref{#1}{#2}. \\ \indent #3}
%% Macro spécifiques à ce fichier (pas forcément)
\newcommand{\dpat}[7]{
\noindent \underline{Pattern} : \textbf{#1}, \indent (type : \textit{#2}) \\
\underline{Description} : \indent #3 \\
\underline{Exemple} : \indent #4 \\
\noindent \underline{Avantages} : 
\begin{itemize}
 #5
\end{itemize}
\noindent \underline{Inconvénients} : 
\begin{itemize}
 #6 
\end{itemize}
\underline{Liens} : #7 
}

%% Infos document
% Titre
\title{Notes sur le module : \textit{Test Driven Developpement.}}
% auteur
\author{Armel Pitelet}
% date de création du document
\date{\today}

%% Glossaire, acronymes et index
\makeglossaries

%% Glossaire et acronyme (déclarations)

% DIP : exemple de formalisme
\newglossaryentry{gl-dip}{
name = {DSP},
description = {la description détaillé}
}
\newglossaryentry{ac-dip}{
type = \acronymtype, name = {DSP}, 
description = {Nom simple}, 
first = {Première occurence\glsadd{gl-dip}}, 
see = [Glossaire:]{gl-dip}
}


\begin{document}
%% Organisation globale 
\maketitle
\tableofcontents

%%--------------------------------------------------------------------------------------------------------------------------------
Sur les types de test, voir \url{https://blog.octo.com/la-pyramide-des-tests-par-la-pratique-1-5/} $\to$ la pyramide des test d'intégration. Faire un test est un compromis entre cout et précision /fiabilité
\begin{itemize}
\item Test unitaire : test d'un block de code le plus petit possible.
\item Test de composant : on test une partie d'une application (une fonctionnalité donnée).
\item Test d'intégration : on test l'ensemble de l'application après l'ajout d'une nouvelle fonctionnalité.
\item IHM (Interface Homme-Machine), aussi appelée de bout en bout (\textit{end to end}) : On démarre l'application et on regarde directement si tt fonctionne correctement.
\item Test de monté en charge (de performance) : pour ne pas dégrader les performances au cours du temps.
\item Test utilisateur : analyse de donnée faite en conception (une fois que tt est développé).\\
\end{itemize}


\note{Pour ce cours on repart de la V3 DemoBinding dans WPF.}\\

\rem{Sur les template de test dans Visual Studio}{On a NUnit, MSTest ou bien XUnit (Il faut privilégier les deux derniers).}\\

\rem{Sur MSTest}{Dans ce template on a une classe annoté \incode{TestClass} et une méthode \incode{TestMethod}.}\\

\rem{Sur les packages interessant}{Via NUget : FluentAssertions : Apporte plus de test par rapport à ce qui est disponible de base}\\

\rem{Sur le test des méthodes Async}{Il faut également que le test associés soit asynchrone.}\\

\section{Unitaire et intégration}

\rem{Sur les conventions de nommage des tests}{Il y a plusieurs méthodes : \url{https://dzone.com/articles/7-popular-unit-test-naming}.}\\

\note{Attention : parfois pour débusquer un bug il est nécessaire d'écrire des programme de test \textit{manuelle} (dans le sens test logique et pas unitaire).}\\

\rem{Sur la visibilité dans les tests unitaires}{On peut passer tt les propr en private mais ce n'est pas forcément une nécissité.}\\

\rem{Sur l'annotation ClassInitialize}{Permet de lancer la méthode annotée une seule fois pour la classe de test en cours. Attention cette méthode doit être static. On pourrait également passer par le constructeur (sans lui donner l'annotation). La version avec annotation fait qq petites optimisations et est donc à préférer. Cependant si il faut initialiser des choses non static il faut passer par le constructeur.}\\

\rem{Sur l'annotation TestInitialize}{Permet de lancer la méthode annotée à chaque tests dans la classe de test.}\\

\note{Pour excécuter les test un par un Il faut passer par le gestionnaire de test de Visual Studio.}\\

\rem{Sur la philosophie des test unitaires}{Pour chaque classe, il faut tester chaque méthode, dans un cas nominal, et dans les cas un peu plus \textit{borderline} qui sont sensé introduire des erreurs.}\\

\rem{Sur l'annotation \keyref{https://docs.microsoft.com/fr-fr/dotnet/api/microsoft.visualstudio.testtools.unittesting.expectedexceptionattribute?view=visualstudiosdk-2022}{ExpectedException}}{Permet d'attendre une exception du type typeof(UneException, potentiellement un message). C'est équivalent un un Assert pour savoir si l'exception à bien été levé.}\\

\rem{Sur les log}{En générale on log les erreurs, les paramètres passées en méthodes (avec \incode{logger.LofInformation}). A utiliser un peu partout (en console+fichier en debug. Uniquement en ficheir en Release). Voir \keyref{https://serilog.net/}{Serilog} et/ou \keyref{https://nlog-project.org/}{Nlog}. Il vaut mieux passer par injection ded épendance pour utiliser les logs.}\\

\rem{Sur la couverture de code}{A partir du moiment ou l'on fait des tests unitaire, on peut regarder la couverture du code (par les tests).}\\

\rem{Si l'on a du mal à tester}{C'est qu'en générale les principes solides n'ont pas été respectés et qu'il faut refactorer le code.}\\

\rem{Sur la répartition des test}{Un projet de test par projet testé, une classe de test par class testée.}\\

\rem{Sur les annotation allant avec la IActionResult}{Elle peuvent servir pour la doc (cad swagger) mais ne change pas le fonctionnement du code.}\\

\rem{Sur les ActionResult et IActionResult}{IActionResult est l'interface implémenté par ActionResult et ActionResult<>. On a pas besoin de spécifier un type de retour autre. IActionResult est plus général et donc à favoriser.}\\

\rem{Sur la notion de code Synchrone}{Le code s'excécute de manière séquentielle.}\\

\rem{Sur la notion de code Parallèle}{Le code s'excécute de manière séquentielle sur plusieurs thread différents (on éxécute deux codes identique ou non en parallèle).}\\

\rem{Sur la notion de code Asynchrone}{Dans le code asynchrone les partie du code marquées \incode{await} peuvent attendre (appel api, bdd) et dans ce cas le reste du code continue à s'excécuter. Async et await laisse le framework décider ou non de créer un nouveau thread pour attendre puis exécuter le code dès que possible.}\\

\note{Au niveau de l'API on voudra des controlleurs asynchrones pour augmenter les performances car on va pouvoir faire plus de requêtes si ces dernières peuvent être mise en attentes.}\\

\rem{Pour les test avec bdd}{Si l'on fait une connection direct il faut bien penser à nettoyer la bdd par la suite. Pour être plus propre on peut passer par le Driver InMemory ou bien SqlLite (en package nugget). Attention au InMemory qui peut avoir des comportement différents d'une base de donnée relationnelle. Voir plutot avec SqlLite (package de EFCore) : \url{https://docs.microsoft.com/fr-fr/ef/core/testing/sqlite}.}\\

\note{Attention à utiliser le moins possible les méthodes déjà existante pour initialiser les test unitaire (pour ne pas risquer d'ajouter un bug dès le début du test).}\\

\rem{Sur les test bdd}{Pour tester certain composant on peut se passer des drivers précédent et isoler les composant à tester via certain frameworks : comme \keyref{https://github.com/moq/moq4}{Moq} qui permet de créer des objets fictifs qui répondent à la même interface que les objets que l'on veut simuler. Voir DemoBindong dans TDD pour implémentation donnée par Nico. On peut donner aux objets Mocks un comportement à avoir. L'intéret est de pouvoir isoler un objet de toutes ses dépendances (ici on test un controller en l'isolant du repository qu'il utilise en créant un mock pour le repository et en lui donnant un comportement attendue pour les fonctions qu'il est sensé avoir via \incode{Setup(repo $=>$ repo.func()).Return(result\_attendue)}.).}\\

\rem{Du détail sur les Mocks}{On peut également vérifier que certaines méthodes on bien été appelée (une et une seule fois, plusieurs fois,... Pour passer des paramètres lors dun \incode{Setup} on peut soit passer un véritable objet soit utiliser le mot clef \incode{It} avec par exemple It.IsAny<Type que l'on veut>()) via \incode{Mock.Verify}.}\\

\rem{Sur la bonne utilisation des mocks}{Ils sont trés utiles pour les test unitaire et de composant mais ne doivent pas être utilisé lors de test d'intégration.}\\

\rem{Pour générer le code coverage}{Il existe \keyref{https://github.com/OpenCover/opencover}{OpenCover}, un outils github pour vérifier le coverage des tests.}\\

\rem{Sur les prérequis pour faire un Mock}{Il faut pouvoir injecter le Mock. C'est primordial, sinon il faut passer par la réflexion, des moyens détournées. Le mieux est d'avoir une interface à injecter.}\\

\rem{Sur le lien entre test de composants et test unitaire}{Il est tt à fait possible d'hériter d'un test de composant pour créer un test unitaire. Il suffit ensuite d'injecter les Mocks. Cela ne fonctionne que si les test sont court et simple. Sinon c'est en générale une mauvaise idée.}\\

\rem{Sur la différence entre un test unitaire et un test d'intégration}{Un test unitaire ne peut pas planter (jamais, sauf problème de code) car il n'est relié à aucun système tier mais uniquement à de la logique. On ne test qu'une logique de code (d'ou les mocks!). Un test d'intégration lui test avec les systèmes tiers branchés. Il peut donc planter.}\\

\rem{Sur la différence entre test de Composant et test d'intégration}{Le test de composant ne test qu'une seule fonctionnalité alors qu'un test d'intégration test l'ensemble des composants (c'est à dire des fonctionnalités).}\\

\rem{Sur l'annotation \keyref{https://docs.microsoft.com/en-us/dotnet/api/microsoft.visualstudio.testtools.unittesting.testcategoryattribute?view=visualstudiosdk-2022}{TestCategory}}{Permet de définir une catégorie de test au niveau des métadonnée. Cela crée une arborescence en fonction des catégroei dans l'explorateur de test. Un peu plus de doc sur l'éxécution des test \url{https://docs.microsoft.com/en-us/dotnet/core/testing/selective-unit-tests?pivots=mstest}.}\\

\section{Test de performance}

\rem{Pour des tests de performances cross version}{On peut utiliser la bibliothèque \keyref{https://benchmarkdotnet.org/}{benchmarkdotnet}. Voir \url{https://benchmarkdotnet.org/articles/guides/getting-started.html} pour un guide de démarrage. Il semble qu'il faille utiliser une console App pour ce genre de test.}\\

\note{Il vaut mieux être dans les même conditions que dans la production pour faire des tests de performances. Par contre il ne faut pas être dans la prod en elle même mais sur un environnement iso-prod (en terme de code mais aussi en terme d'architecture logiciel et infrastructure).}\\

\rem{Sur l'attribut \keyref{https://benchmarkdotnet.org/articles/features/setup-and-cleanup.html}{GlobalSetup}}{Permet de donner un environnement global aux tests de performance. La méthode marqué par cette attribut sera appelée une seule , avant l'excécution de tt les tests marqués \keyref{https://benchmarkdotnet.org/articles/features/baselines.html}{Benchmark} qui marque une méthode comme à 'benchmarker'. Ce test la permet de comparer les performancances de différents algorythme.}\\

\note{Il faut penser à passer la génération en mode release pour les tests de performances.}\\

\rem{Sur l'attribut \keyref{https://benchmarkdotnet.org/articles/configs/jobs.html}{SimpleJob}}{Permet via RuntimeMonikor de tester différent type de runtime (comme .net 5 vs .net 6).}\\

\note{Après un test on peut exporter les résultats d'un test sous forme de graphique. Peut être utile pour garder une trace et comparer en fonction des versions des projets.}\\

\rem{Pour faire du Parallel}{On doit passer par la bibliothèque parallel.}\\

\rem{Pour tester les performance de l'API}{On peut passer par la bibliothèque \keyref{https://gatling.io/}{Gatling}. C'est plutôt un outil Java, même si on peut l'utiliser dans dotnet en passant par du Scala (encore un nouveau language). On passera plutôt par \keyref{https://nbomber.com/}{NBomber}. NBomber fournit un .html à la fin des tests qui résume les tests.}\\

\rem{Sur Test de charge et test de performance}{Avec Nbomber on test la performance d'une API (on est donc proche du test end-to-end ou d'intégration). Benchmark Dotnet lui sert plutôt à comparer plusieurs algorythme en terme de performance (proche du test unitaire).}

\rem{Sur le ScenarioBuilder}{Cela permet de configurer les conditions de tests.}\\

\rem{Sur la notion de WarmUp}{Le WarmUp est une étape de \textit{chauffe} de l'API. Vu qu'en C\# le compilateur fait du JIT (Just in Time), il y a qq optimisations qui ne sont appliqués qu'après qq utilisation du code. La période pendant laquelle ces optimisations ne sont pas encore effective est appelée le WarmUp.}\\

\note{NBomber permet également de monitoré l'utilisation matériel pendant les tests.}\\

\note{Ce genre de tests de performance sur l'API est qq chose de très fréquent. L'idée est de suivre dans le temps l'évolution des performance du programme. C'est aussi intéressant pou r\textit{sizer} une application c'est à dire avoir une idée du matériel nécessaire pour utiliser une application (en fonction de la charge demandée).}\\

\rem{Sur les outils natif pour des test de performance}{voir \url{https://docs.microsoft.com/fr-fr/dotnet/core/diagnostics/dotnet-trace}.}\\

\rem{Pour tracer les fuites mémoire}{Il faut passer par les commandes \keyref{https://docs.microsoft.com/fr-fr/dotnet/core/diagnostics/dotnet-dump}{dotnet dump} qui permettent de récupérer ce qu'il y a dans la mémoire.}\\

\rem{Sur une alternative au pattern factory}{Voir le pattern \keyref{https://refactoring.guru/design-patterns/builder}{builder}}\\

\rem{Sur le test d'un site internet (Notre site Angular)}{On peut utiliser \keyref{https://github.com/cypress-io/cypress}{cypress}. Il est possible de le mettre dans la chaine d'intégration continue. Il peut prendre des screenshot des events qui ne se déroulent pas comme attendue. Pour un guide démarage voir : \url{https://docs.cypress.io/guides/getting-started/writing-your-first-test\#Add-a-test-file}.}\\

\rem{Liens utiles}{awesome X dans une recherche permet d'avoir des pages qui regroupent l'ensemble des technos les plus appréciés et utilisés par la communauté. Voir par exemple \url{https://github.com/quozd/awesome-dotnet}.}\\

\rem{Sur les tests en WPF}{On passe par ce drivers : \keyref{https://github.com/microsoft/WinAppDriver}{WinAppDriver} (Exe à récupérer, à installer puis lancer au click ou en ligne de commande [penser à l'ajouter au path]). Une fois mis dans le path on peut le lancer en ligne de commande via WinAppDriver Nport ou Nport est le port à donner. Il faut ensuite dans les package nugget passer par Appium.Webdriver (dans visual studio) et utiliser une classe de configuration (voir exemple de nico) dans lequel on indique le Nport également (il faut être cohérent avec celui donné lors du lancement du driver). A partir de la on crée des classes de test.}\\

\section{Divers}

\rem{Sur la philosophie de test}{Lorsque l'on galère à faire les tests unitaire c'est qu'il y a un problème de conception dans le code. Souvent car les logiques ne sont pas séparés. C'est l'un des intêret des test. Il ne faut pas non plus changer le code pour les test, mais les tests permettent de mettre en lumière des problèmes de conception}\\

\note{Si l'on veut faire du SQLite (base de donné dans un fichier .db) il suffit d'ajouter :memory après le Data Source = MaBase.db.}\\

\rem{Sur le "Data Source"}{On peut donner un path relative (../MonDbContext pour remonter ailleurs) ou bien un path absolue. Par défaut le relatif est sous entendu : Demo.db est équivalent à ./Demo.db.}\\

\rem{Sur le suffixe Async}{La bonne pratique était de suffixer les méthodes avec Async mais au final cela n'est utile que lorque l'on à les deux (sync et async).}\\

\rem{Sur une alternative à Autofixture}{Voir \keyref{https://github.com/bchavez/Bogus}{Bogus}. Semble plus simple à configurer.}\\

\rem{Sur le mapping d'exceptions}{Il est interessant de mapper des Type d'exceptions aux codes de retour Http.}\\

\rem{Sur une bonne source d'information}{Voir le github \keyref{https://github.com/dotnet-architecture}{dotnet-architecture}.}\\

\rem{Sur l'interet du repository}{L'interet est de séparer la logique de la base de donnée de la logique des controller (gestion des http).}\\

\rem{Une discussion interessante sur la différence entre Mock et Stub}{voir \url{https://martinfowler.com/articles/mocksArentStubs.html}.}\\

%%--------------------------------------------------------------------------------------------------------------------------------1
%% Glossaires


\end{document}
\end{document}
